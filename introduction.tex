\chapter{Introduction}
\label{introduction}

\section{Rationale}

Recent changes in the direction of computer hardware development have
created an impasse in the domain of software engineering.  Over the
past few years, new microprocessors have not seen the same increase in
clock speed that has prevailed over previous decades.  Instead, the
use of multiple `cores' has become common, due largely to physical
limitations which prevent the individual elements of a single
processor core becoming any smaller.  As a result, the performance
benefits of these new processors arise not from being able to execute
a single task faster than before, but from the parallel execution of
many such tasks.

However, this leads to a problem.  The existing dominant methods for
designing software systems are inherently sequential.  Current
imperative and object-oriented programming languages are still founded
on the principles of early computational models, such as the Turing
machine \cite{turing:36}.  These take an idealised view of events
where they always occur sequentially and in isolation.  Programs are
thus still effectively written as a sequence of reads and writes to a
form of memory.  The problem with this approach is that it runs into
major issues when the execution of other programs may cause changes to
memory outside the remit of the program.  Imagine Turing's model but
with multiple heads, each running separate programs yet still sharing
the same tape -- what happens if more than one head writes to the same
area of the tape?

In this thesis, we advocate a move towards systems where the focus is
on interaction between minimal sequential subsystems.  Rather than
building huge monolithic structures, the same result can be achieved
using a number of smaller components, running in parallel.  Such a
strategy has been suggested in varying forms over the years, but due to
the perceived future evolution of the microprocessor, this is now an
essential requirement, rather than a design ideal or optimisation.  We
also provide a formal grounding for such designs, based on academic
research which has been largely overlooked in the industrial sector.
Security also forms an inherent part of both the design and formal
model by allowing restrictions to be imposed on the communication
between individual components.

In the remainder of this chapter, we provide a brief overview of the
evolution of concurrent processing, highlighting current issues
arising from the flawed approach of maintaining a sequential design
which is becoming more and more distant from reality.  We also look at
how restricted mutability and an emphasis on intercommunication
between smaller, more specific processes can provide a better
solution, and how this approach has been adopted in the past with
varying success.  We close with a summary of the novelty of this work,
and an overview of how this will be covered in the later chapters of
this thesis.

\section{The Current Status Quo}

\subsection{Multiprogramming}

Concurrency is nothing new.  The concept of executing multiple
programs at the same time has been in use since
\emph{multiprogramming} was first introduced back in the 1960s.  But
the same underlying model has remained.  Parallelism is still seen as
an optimisation, beholden to the maintenance of the sequential
standard.  Utilising concurrency within a program remains relegated to
study as an advanced feature, seldom taught and even less well
practiced.  If parallelism is to become the dominant means of
exploiting the power of future hardware, this needs to change.

Multiprogramming was introduced as an efficiency measure.  At the
time, machines were available only on a per-institution rather than
per-user level, so a batch of \emph{jobs} were submitted to the
machine, each consisting of the program to run and any associated data
it needed to do so.  The machine ran a relatively simple
\emph{operating system}, which would take each job in turn and execute
a specified series of commands written in a batch job language.  Such
jobs would usually consist of reading in the program, compiling it if
necessary, and then executing it.  During execution, data was read in
and the results of computation output for the user to later digest.

It soon become clear that having an expensive processor sit idle while
input/output (I/O) operations took place was wasteful.  To solve this
problem, a new generation of machines were introduced which provided a
\emph{scheduler} as part of the operating system.  Instead of running
each job to completion before attempting the next, the system read in
multiple jobs to begin with, each forming a \emph{process} in memory.
These processes consisted not only of the code being executed, but
also included contextual information, such as the current instruction
being executed (the \emph{program counter}) and environmental data
(e.g. open file handles).

If a process being run by the system reached a point where it had to
wait for an I/O operation, the scheduler would move the process into a
\emph{blocked} state and perform a \emph{context switch} to begin the
execution of another.  Once the I/O operation was complete, the
blocked process would be reassigned to a \emph{ready} state, making it
again eligible for execution.

All this remained completely invisible to the running processes, each
of which appeared to be running in complete isolation.  The hardware
provided memory protection, which prevented a process from accessing
data outside its own memory space and they remained largely oblivious
to the fact that their execution was effectively being paused and then
resumed later.  The effect of such operation was only noticeable if
the running time of the process was recorded, as such results were now
dependent on factors such as system load and the arbitrary choices of
the scheduler.

Over time, schedulers have been extended so as to also switch when a
quantum of time allocated to a process has been depleted.  This
ensures a greater degree of fairness; a processor-intensive task which
rarely blocks can no longer become overly dominant.  For batch
systems, this wasn't of great importance (provided the process
eventually terminated) as users submitted a job and then collected the
results later on.  In this context, just utilising the time when a
process was blocked had a significant impact on perceived performance.
However, with a move towards first time sharing and then personal
computer systems, it became necessary to ensure that each process was
given time to execute on a regular basis, so the system remained
responsive.  This concept is referred to as \emph{preemption}.

Finally, further performance enhancements were made possible by
allowing processes to have multiple threads of control and extending
the scheduler to enable switching between the individual threads
within a process.  The advantage of such threading is that the threads
share the same memory space and thus may interoperate more easily and
more efficiently.  The disadvantage is that it makes the possibility
of \emph{contention} much more likely.

\subsection{Resource Contention}

Concurrency issues arise when multiple processes or threads contend
for access to the same resource.  With threads, this is a frequent
occurrence as they run the same code and access the same variables.
It also occurs with processes; although they have their own memory
space in which to operate, the resources provided by the underlying
operating system are shared by them all.  An obvious example is the
filesystem.  What happens if more than one process tries to access a
file at the same time?  Unless only reads occur, the possibility of
data corruption arises.

Such bugs, known as \emph{race conditions}, are difficult to reproduce
as they are heavily dependent on timing.  This is especially true of
single processor systems, where concurrency is merely simulated by the
scheduler switching between processes.  Whether or not file corruption
occurs depends on the choices made by the scheduler, which in turn
depends on a number of factors, such as system load.  If many
processes are competing for the processor, then there is less chance
of one which accesses the same file being picked.

A print spooler is a program which allows a printer (another shared
resource) to be used by many processes while maintaining separation
between individual jobs.  Without such a mechanism, one program may
write a few lines to the printer, and then be suspended by the
scheduler.  The program which is allowed to run next may then also
write to the printer, causing the user to end up with output from
different jobs mixed together.

Instead, the spooler tackles this concurrency problem by acting as an
mediator between the programs and the printer.  However, such an
application must be carefully designed to ensure it doesn't fall foul
to the same issue.  Imagine the spooler operates by reading a list of
files to print from a shared file.  When a process wants to add a new
job to the queue, it writes the filename as a new entry at the end of
the file:

\begin{verbatim}
int fd = open("/var/spool/print_jobs");
seek(fd, END_OF_FILE);
write(fd, "my_print_job");
close(fd);
\end{verbatim}

Problems arise because such an operation is \emph{non-atomic}; it is
possible that the process may be stopped by the scheduler while adding
a job to the list (e.g. after the \texttt{seek} function above), just
as it may be stopped while writing to the printer.  If this happens,
there is a possibility that whichever other process is scheduled in
its place could also choose to alter the queue.  The result of such a
collision depends on the timing:

\begin{enumerate}
\item If the first program only opened the file, or was just about to
  close it, then there will be no consequence.  In the first case, the
  first program will move to the end of the (now longer) file when it
  resumes and write its entry.  In the latter case, closing the file
  is just a matter of freeing resources and has no effect on the file
  itself.
\item If the first program seeked to the current end of the file, then
  on resumption, it will overwrite any data added in the meantime.  If
  the new data is longer than the older data, then the old data will
  simply be lost.  If it is shorter, the file will be corrupted.
\end{enumerate}

The solution to these sort of problems is to limit access to a
resource, so that a process is forced to wait its turn.

\subsection{Semaphores and Monitors}
\label{semaphores}

Such access limitations can be imposed by a \emph{semaphore}, a
solution first proposed by Dijkstra\cite{semaphore}.  A semaphore
maintains an integer count which is manipulated by two operations: \texttt{up}
and \texttt{down}.  The count can be used to limit the number of threads of
control active in a particular region.  In effect, this is akin to the
scenario where a gate requires a token in order to allow someone (a
thread) to pass through, but the number of such tokens is limited.
When a thread wants to pass through the gate, it attempts to acquire a
token by executing the \texttt{down} operation.  If the count maintained by
the semaphore is greater than zero, then it will be decremented and
the thread can proceed through the gate.  However, if it is zero,
there are no tokens left so the thread is forced to wait until one of
the existing tokens is returned.  Tokens are returned by executing the
\texttt{up} operation.

The \texttt{up} and \texttt{down} operations must be atomic; it should
not be possible for such an operation to be interrupted.  If they can
be, then the whole purpose of the semaphore is defeated; a further
solution would be needed to resolve the possible concurrency issues
that may occur inside the semaphore itself.  Most operating systems
provide such atomicity by using support available at the processor
level; a Compare And Swap (CAS) operation updates a memory value only
if the current value matches the one given as an argument (i.e. it
hasn't been changed by another process or thread).

\emph{Binary semaphores}, where the count is either zero or one, are
very common.  Such semaphores can be implemented in a simplified form
known as a \emph{mutex}, which maintains a binary state
(locked/unlocked) rather than a count.  Locking a mutex is equivalent
to decrementing the count to zero via a \texttt{down} operation, and unlocking
it is the same as performing an \texttt{up} to return its value to one.  The
usage pattern is the same for both: a thread first locks the mutex,
does its work and then unlocks the mutex to allow others access.

Mutexes can also be implemented at the file level as file locks,
providing a solution to the problem we encountered in the previous
section:

\begin{verbatim}
int fd = open("/var/spool/print_jobs");
flock(fd, LOCK_EX);
seek(fd, END_OF_FILE);
write(fd, "my_print_job");
flock(fd, LOCK_UN);
close(fd);
\end{verbatim}

The first call to \texttt{flock} acquires an exclusive lock
(\texttt{LOCK\_EX}) on the file referenced by \texttt{fd} (the file
descriptor returned by the operation which opens the file).  Let's
assume that this process is stopped by the scheduler after the
\texttt{seek} function executes and another process is allowed to run.
This second process executes the same program.  While it can
successfully acquire a file descriptor for the file through the
\texttt{open} function, the \texttt{flock} function will block trying
to obtain an exclusive lock.  This is because the lock is still held
by the original process which has been descheduled but has not yet
relinquished the lock.  When the original process is chosen again by
the scheduler, it can continue to write to the file, safe in the
knowledge that no other process has altered its contents in the
interim.  The final call to \texttt{flock} releases the lock so the
second process may now proceed.

Semaphores also have signalling capabilities; threads waiting to
perform a \texttt{down} operation are woken when an \texttt{up} occurs
on the same semaphore.  They can then retry the \texttt{down}
operation again and return, having decremented the value of the
semaphore, should the operation succeed on this attempt.  Given that
there may be multiple waiting threads, there is no guarantee that a
thread will become active; for each \texttt{up} operation, only one
\texttt{down} operation will be successful and any other threads will
again be forced to wait.  Again, this race is why it is essential that
the \texttt{down} operation itself is atomic.

Suppose we want to implement a bounded buffer which is accessed by
multiple threads.  We need to use semaphores both to prevent possible
race conditions when modifications are made to the buffer, and to
stall threads when the buffer is full (in the case of adding a new
item) or empty (when retrieving an item).

As in our previous example, a binary semaphore or mutex can be used to
make modifications to the buffer appear atomic; a thread wanting to
operate on the buffer needs to first acquire the token and will be
unable to do so if another thread has already taken it.  Semaphores
can also be used to monitor the state of the buffer, and provide
notifications to the producer and consumer threads when the buffer
empties or fills up, respectively.

\begin{verbatim}
produce()
{
  item = produce_item();
  down(empty);
  down(mutex);
  add_item_to_buffer(item);
  up(mutex);
  up(full);
}

consume()
{
  down(full);
  down(mutex);
  item = remove_item_from_buffer();
  up(mutex);
  up(empty);
  consume_item(item);
}
\end{verbatim}

The above example provides an example implementation of such a buffer,
using three semaphores: \texttt{mutex}, \texttt{empty} and
\texttt{full}.  The \texttt{mutex} semaphore is a binary semaphore,
which ensures a thread has exclusive access to the buffer by making
modifications to the buffer appear atomic; although the thread can
still be interrupted, any other threads trying to execute
\texttt{down(mutex)} will be blocked until the original thread
relinquishes control.

The other semaphores are used to maintain a count of how many empty or
non-empty slots are available in the buffer.  As the buffer is filled,
the number of empty slots goes down and the number of non-empty slots
goes up.  The inverse is true when the buffer is emptied by the
\texttt{consume} function.  The \texttt{empty} mutex is initialised
with a value equal to the size of the buffer, while the \texttt{full}
mutex begins with a value of zero.

In the \texttt{produce} function, the thread first checks if there are
any empty slots by performing a \texttt{down} operation on the \texttt{empty}
mutex.  If the \texttt{empty} semaphore has a non-zero value, as at
the beginning, then there are available slots in the buffer and the
operation will return after decrementing the value by one.  In this
case, the thread can then proceed to lock the buffer using the
\texttt{mutex} and add an item to it.  It then releases the
\texttt{mutex} and performs an \texttt{up} operation on the \texttt{full}
semaphore, increasing the number of slots in use and potentially
allowing those threads waiting in the \texttt{consume} function to
proceed.  The \texttt{consume} function is effectively the inverse of
the \texttt{produce} function; it checks the number of full slots to
begin with, using the \texttt{full} semaphore, and increases the
number of empty slots when done.

The examples above are fairly simple, but already demonstrate some of
the problems inherent with the use of semaphores.  A successful
strategy for using them requires placing acquisition and release calls
in all affected locations and is extremely prone to error.  Suppose
one of the processes above never relinquishes the lock on the file.
Or a thread never performs an \texttt{up} on the mutex.  Other threads or
processes wishing to acquire the lock or mutex will be blocked
forever.  Similarly, it takes only one miscreant to access the shared
resource without attempting to acquire a lock to make the whole
process of locking redundant.

Semaphores don't scale well either.  For even a small program like the
buffer example above, three semaphores are required.  In such a
situation, the order of acquisition also becomes important.  If the
order is wrong or differs between code segments, deadlock can occur.
Deadlocks happen when each process or thread is waiting on a resource
held by another waiting process.  In the buffer example, simply
altering the order of the \texttt{down} calls in the \texttt{consume}
function is enough to create a potential deadlock situation.  If a
thread manages to acquire the mutex but is then forced to wait for an
\texttt{up} on the \texttt{full} semaphore, no other thread will be able to
acquire the mutex in the meantime.  Only in the unlikely situation
that a thread has been stopped between the \texttt{up(mutex)} and the
\texttt{up(full)} calls in the \texttt{produce} function would this
deadlock be resolved.  In most cases, the other threads will attempt
to acquire the mutex before reaching the required \texttt{up(full)}
call and so are left waiting forever.

By far the biggest issue with these kind of problems is
reproducability.  Just as with the race conditions they are trying to
avoid, bugs relating to semaphores may not always manifest themselves.
The example above is very likely to result in deadlock, as it just
requires the \texttt{consume} function to be called when the buffer is
empty and no other thread is accessing it.  Other issues can be much
harder to diagnose.

Take two processes, A and B, both of which are trying to acquire a
lock on the two files, \texttt{/etc/passwd} and \texttt{/etc/shadow}
in order to add a new user to the system.  If both processes acquire
the locks in the same order, then all is well.  If they don't, a
deadlock may occur.

Let's assume process A runs first.  It acquires a lock on
\texttt{/etc/passwd}.  At this point, A has used its allocated quantum
of processor time and so is descheduled.  A context switch occurs and
process B begins to run.  If B begins by trying to acquire a lock on
\texttt{/etc/passwd}, then it will simply block as A already holds
this lock.  If, however, it tries to acquire a lock on
\texttt{/etc/shadow} first, this will succeed.  We then get stuck in a
deadlock; B blocks trying to acquire the lock on \texttt{/etc/passwd}
held by A, which will never be relinquished because A will be blocked
trying to acquire the lock on \texttt{/etc/shadow} held by B.  Such
problems occur simply through an ordering mismatch, but can be
extremely difficult to catch; in many situations, the process will
acquire both locks without being descheduled inbetween.

The solution to these problems is to abstract away from such intimate
details and allow the programmer to work at a more amenable level.
One attempt at doing so can be seen in the use of \emph{monitors}
\cite{mon1, mon2}.  Rather than worrying about the placement and
sequencing of individual acquisition and release calls, the programmer
simply denotes which sections of code must be run in mutual exclusion
from one another.  The compiler or virtual machine (depending on
whether the code is pre-compiled or not) then handles the process of
adding the required statements to ensure this.  The concept of
monitors is strongly linked to the idea of \emph{objects}, with the
same common idea of data encapsulation; all variables are private to
the object and inaccessible from the outside.  To read or modify the
data held by a monitor, one of its methods must be called.  Once a
thread is running code in a particular method, no other thread may
enter a method belonging to that monitor.  This ensures the thread
safety of the data without the issues of acquiring locks and lowers
the potential for deadlocks.

While this provides a better alternative to the use of binary
semaphores or mutexes, for a scenario such as the buffer example a
notification mechanism is required so that threads can wait for a
particular event to occur and be notified by other threads when it
does.  Monitors provide for this via the use of \emph{condition
  variables} and the \texttt{wait} and \texttt{signal} primitives.
Just as with semaphores, one thread calls the \texttt{wait} operation
on a particular condition variable and then another thread calls
\texttt{signal} on the same variable when the situation has changed.
The problem with this approach is that it is just as prone to error as
the use of semaphores; if the \texttt{wait} and \texttt{signal}
primitives are not used appropriately, then threads may be stalled.
It is still a very low-level solution.

Another issue with monitors, as implied above, is that they are
heavily reliant on support from the programming language being used.
While semaphores just require some means of performing an atomic
change to an area of memory, monitors need the compiler or virtual
machine to be intelligent enough to parse the monitor structures and
convert them into appropriate uses of more low-level locking
constructs.  One language in which support is provided is Java, as can
be seen in the example below:

\begin{verbatim}
public class Buffer
{

  public static final int BUFFER_SIZE = 5;

  private int used = 0;
  private Object buffer[BUFFER_SIZE];
  
  public void produce()
  {
    Object item = produceItem();
    synchronized
    {
      while (used == BUFFER_SIZE)
        wait();
      buffer[used] = item;
      ++used;
      notifyAll();
    }
  }

  public void consume()
  {
    Object item;
    synchronized
    {
      while (used == 0)
        wait();
      --used;
      item = buffer[used];
      notifyAll();
    }
    consumeItem(item);
  }
}
\end{verbatim}

This is a implementation of the buffer example using monitors rather
than semaphores.  There are two main differences between the Java
implementation of monitors and that proposed in the academic
literature: the mutual exclusion is limited to blocks of code marked
with the \texttt{synchronized} keyword, rather than encompassing the
whole class, and the \texttt{wait} and \texttt{signal} operations are
realised as the \texttt{wait} and \texttt{notifyAll} methods of the
\texttt{Object} class rather than being functions applied to condition
variables.  One downside of these changes is that the addition of
selective mutual exclusion makes it prone to error; although it is
more efficient not to lock the entire class whenever any method is
called, this also means that one may forget to use the
\texttt{synchronized} keyword just as one may forget to perform the
appropriate operation on a semaphore.

The similarities and differences between monitors and semaphores can
be clearly seen by comparing the two buffer examples.  In the Java
version, the use of the \texttt{empty} and \texttt{full} semaphores is
replaced by a while loop and the use of \texttt{wait()} and
\texttt{notifyAll()}.  The value these depend on is also made explicit
in this version (see the variable \texttt{used}), whereas it is an
implicit part of the operations on the semaphores in the earlier
example.  When \texttt{produce} is called, it tests to see if the
buffer is full (the \texttt{used} count is equal to the size of the
buffer).  If it is, then \texttt{wait} is called.  The test takes
place in a \texttt{while} loop rather than a single \texttt{if}
statement so that the condition is tested again when the thread is
awoken by the \texttt{notifyAll()} call.  As before, if many threads
are waiting, it may be the case that the buffer is already full again
by the time a particular thread is allowed to execute.

The \texttt{synchronized} blocks behave in a way equivalent to those
protected by the \texttt{mutex} semaphore; the opening bracket is the
\texttt{down} operation, while the closing bracket is the \texttt{up}.
Once a thread is executing code inside one of these blocks, no other
thread may enter such a block, whether this be the same one or another
in the same class.  Modifications to the \texttt{buffer} and
\texttt{item} variables only take place within these blocks, thus
ensuring that only one thread can change things at a time.  Both
variables are marked \texttt{private}, making them invisible to code
outside this class.

What is clear from our comparison is that there are few advantages to
using monitors; they are prone to similar low level errors to those we
saw with semaphores, and they also require support from the language
being used, which may not always be available.  Ideally, we instead
need to take a step back and limit the need for such locks altogether
by reducing the number of shared resources and the amount of
mutability inherent in our designs.  Not only are existing designs
prone to error, but they also reduce the advantages of concurrent
processing (having to acquire a lock effectively makes operations
single-threaded once again) and are reliant on the existence of some
form of shared memory.  In distributed systems, shared resources do
not exist naturally but must instead be created artificially and may
make processing more inefficient.  In the future, we want to be able
to utilise the advantages of massively parallel systems and this can
only be achieved by reducing the need for resource contention.

\subsection{Interprocess Communication}
\label{ipc}

To achieve this, we need to focus on more short-lived processes which
interact directly with one another, rather than via the means of
shared resources.  This is nothing new.  However, it has never
achieved universal acceptance as a design paradigm because having to
deal with the kind of concurrency issues outlined above has
traditionally been avoidable.  This is no longer the case.

Although mainstream development has migrated from procedural programs
to the \emph{object-oriented} paradigm, programs, once compiled, still
tend to be monolithic entities, with generally only a single thread of
control.  The notion of objects we see being used is not that of
Simula\cite{simula}, where they are \emph{task-centric} units with
their own behaviour.  Instead, it is one which is much more
\emph{data-centric}.  These objects allow data to be separated out
into neat little bundles and stimulate reuse by allowing hierarchies
of derived behaviour to be created.  But there is no relationship
between objects and threads; when a method of an object is called,
control switches from one object to another.  If multiple threads are
in use, then the objects are shared between them and we see the kind
of problems described above.

Solving this takes more than simply establishing a one-to-one
relationship between threads and objects, because each unit is
designed with a focus on the data being stored and not on the task
being performed.  Thus, for most designs, having an object per thread
would be terribly inefficient and, in some cases, preposterous.  For
example, an implementation of a library system would have a
\texttt{Borrower} object.  A typical system may have thousands of such
borrowers, many of which are inactive for weeks or months at a time.
Having a thread for each would be ridiculously wasteful.

Instead, the solution is again to use objects which are task-centric.
In the library example, the objects would focus on jobs such as
issuing and returning books, and dependent tasks such as obtaining
data on a borrower or book from the database.  In either scenario,
there will be contention for database access, but in the task-centric
variant, an object can be given the job of a database guardian,
centralising all data storage issues in one place.

There are many existing examples of this kind of \emph{component} or
\emph{service}-based design, but they have so far failed to become the
mainstream approach.  One of the earliest is the notion of pipelines
between processes, which originated from UNIX systems\footnote{Other
  systems have since adopted this technique, including those such as
  MS-DOS which are single-tasking and thus can not actually pass data
  between two processes.  Instead, they make use of
  \emph{pseudo-pipelines}, where the first program outputs data to a
  temporary file and the second then reads its input from that file.}.
Early UNIX programs were developed with the aim of doing a single task
and doing it well, unlike the feature bloat apparent in many of
today's applications.  For example, the command \texttt{du}, which
calculates disk usage, doesn't include an option to sort the results.
This is because there also exists a command, \texttt{sort} which can
order an arbitrary block of text in a number of ways.  As such, there
is no point adding duplicate functionality to \texttt{du} when its
output can just be fed in as input to \texttt{sort} for those who
desire this feature.

A pipeline is created in the shell by separating the two programs with
a \texttt{|} symbol.  For our example, \texttt{du -h | sort -n} would
do the job of outputting disk usage in human-readable form
(\texttt{-h}) and then sorting it numerically (\texttt{-n}).  A
similar solution can be applied programatically using system calls
such as \texttt{pipe}, \texttt{fork} and \texttt{execve}.  The pipe
allows the output of one program (\texttt{du}) to become the input of
another (\texttt{sort}).  Neither of the individual programs needs to
be aware that this is happening.  As far as \texttt{du} is concerned,
it is still sending output on its standard output channel.  The
difference is that this channel has been changed externally so as to
feed instead into a pipe, the other end of which forms \texttt{sort}'s
standard input channel.

This is a very simple solution, yet it elegantly solves the problem of
sharing the data between the two processes.  If a pipe was not used,
\texttt{du} would have to store its results somewhere for
\texttt{sort} to access.  This could then result in contention between
the two processes for access to the resource.  Instead, here the two
are working together rather than against each other by synchronising
the passage of data between them.  Each is independent of the other
and specific to its purpose.

\emph{Microkernels} such as Mach\cite{mach}, MINIX 3\cite{minix3} and
the GNU HURD\cite{hurd} also utilise this idea of synchronous
communication rather than a monolithic design based around shared
resources.  In this context, it provides an essential stability and
security advantage; many services, such as device drivers, file systems and
network protocols, can operate at a similar level to user processes.

Some elements of the kernel require specialised operations which are
only available when the processor is in a \emph{privileged} mode of
operation.  As they are generally unique to a particular processor
architecture, they also require the code to be written in assembly
language.  However, these restrictions need not apply to the entire
kernel.  Device drivers are particularly notorious for causing system
instability by having this level of control.  This is especially true
when such drivers are provided by third parties who are not as
familiar with the operating system code as the core developers.

To combat this, in MINIX 3, device drivers operate as separate
privileged processes.  Unlike normal user-level processes, they have
the ability to request direct access to hardware but such access is
achieved by passing messages to a minimal kernel.  The majority of the
driver's operation takes place in userspace and any low-level access
can be monitored and potentially prohibited.  Other components can
operate with even fewer privileges; file systems and network protocols
need only the means to transfer a sequence of bytes to disc or down
the wire.

The Mach kernel, developed at Carnegie Mellon University, takes a
similar approach with the central mantra being one of multiple
servers, which provide different operating system services.  The GNU
HURD kernel is currently based on Mach, though a number of more recent
microkernels are now being considered, due to issues with Mach's
design \cite{hurd:critique}.  Apple also adopted this design for XNU,
the Mac OS X kernel, but, while basing it on Mach, they greatly
reduced the design to a single server running a monolithic BSD-based
kernel.  MINIX 3, XNU and the HURD all try to implement a
component-based design while retaining compatibility with existing
monolithic UNIX systems, and so compromises have to be made.  While
Mac OS X is easily the most widely used of these examples, it has had
to sacrifice the most to achieve this.

The traditional objection against such designs has been performance.
Designs based on intercommunication have always tended to be more
elegant, but their usage has tended to be restricted to distributed
systems such as web services.  In these circumstances, any design
approach necessitates utilising a potentially slow connection to
another system, and having a central resource upon which all others
rely becomes disadvantageous, due to the potential for failure.  That
said, the most popular web services in use today do not follow the
component-based design that would allow the dream of composite web
services \cite{cashews-sem} to become a reality; the likes of
\emph{Facebook}, \emph{Twitter} and \emph{Last.fm} \cite{facebook,
  amazon, twitter, lastfm} all provide web service interfaces which
simply wrap an earlier monolithic object-oriented design.  Others,
such as \emph{Amazon} \cite{amazon}, now focus on providing a utility
service, offering processing power and storage for a price, while
\emph{Google} \cite{google} prefer to target users with complete
applications.

We believe it is time to reevaluate the benefits of systems focused on
intercommunication between specialised components.  With modern
systems, the potential performance disadvantage is becoming outweighed
by the benefits of a cleaner and more sustainable design.  With the
increasing prevalence of truly concurrent systems, monolithic designs
will face a clear disadvantage, as the potential for parallelism is
severely reduced by contention for shared resources.

\section{Our Proposed Solution}
\label{solution}

There are already many examples of computational models which
represent concurrent behaviour and its issues in the academic
literature.  We will cover some of these in depth in chapters
\ref{apc}, \ref{globsync} and \ref{mobility}.  However, these have
been largely ignored by the software industry, as has one of their
main uses; formal verification.  This is primarily due to inertia;
developers have little time to invest in learning new techniques and
so stick to those they know and which have proved successful in the
past.

Change does occur when there is little other sensible choice and it
makes good business sense to do so.  We have already seen this with
object-oriented programming (OOP). It took about twenty years for OOP
to become widely adopted from its initial inception in academia, and
then, as we discussed in \ref{ipc}, it was in a form much closer to
existing sequential models.  The change happened as programs became
larger and their design made them more and more unmaintainable, to the
point where the cost of doing so was more than adopting a different
technique, in this case OOP.

We have reached an equivalent juncture now with relation to
concurrency.  Programs have continued to become larger and more
bloated with features, but the increasing speed of microprocessors has
allowed a state of equilibrium to be maintained.  This is no longer
so.  Now, when users go out to purchase a new computer, they are
likely to get one with twice the number of processors than the one
they had before, rather than twice the speed.  Because their programs
will be largely monolithic, they won't see much of a performance
increase in their new purchase; the same application will still be
running on a single processor of about the same speed.

We are not the only ones to observe this need to make concurrency more
central to the design process.  With the recent release of Mac OS 10.6
(\emph{Snow Leopard}), Apple have introduced a new application
programming interface (API) called \emph{Grand Central}
\cite{grandcentral}, which shifts the responsibility for managing
threads to the operating system.  Developers instead design their code
as a series of tasks, which are submitted to the operating system
through the API.  They are then later scheduled and executed using a
pool of threads; this allows threads to be reused and thus increases
performance by reducing the amount of thread creation that takes
place.  A similar approach is available to Java developers, which we
discuss in detail as part of \ref{java:concurrency}.

Thus, software designers need to seriously start thinking about how
they can best utilise this new hardware and this undoubtably requires
a shift in the underlying design.  What we propose here is a
compromise; we introduce a new framework, DynamiTE (see chapter
\ref{dynamite}) with a task-oriented design methodology, which
retains as many familiar ideas as possible.  Unlike efforts such as
\cite{obliq}, \cite{daveturner:phd}, \cite{wojciechowski:phd} and
\cite{sangiorgi:safeambientsmachine}, we avoid introducing a
completely new programming language.  Instead, we build on top of an
existing one (Java) which is already familiar to many software
developers and which uses constructs with which they are already
familiar.  In doing so, we remove a huge barrier to adoption; the
implementation of the framework is no longer some mysterious mass of
code written in an obscure functional language, but a Java library
like any other which developers may even be able to contribute to with
time.  In this form, it still provides the advantage of abstracting
away from many of the low-level details we saw in \ref{semaphores},
while also being much more approachable.

We still follow these earlier examples in basing the framework on a
theoretical model.  This allows us to leverage years of academic work
in this area, and allows for the possibility of reasoning over such
programs in the future.  However, we approach this from the point of a
view of a software developer wanting an implementation with the
benefits of a theoretical basis, rather than as a process algebraist
looking to write code in their favourite calculus.

To this end, we base our framework on our own calculus, which is
compromised of what we believe to be some of the best of the existing
ideas present in the literature.  We believe our particular
combination to be novel, as are the way in which some features are
presented, in particular the notion of `bouncers'; its formation and
use is discussed at length in chapters \ref{nt} and \ref{tnt}.
However, our primary aim is not to provide a vastly superior calculus,
but one which best suits its position at the core of our framework.

\subsection{A Prototypical Application}
\label{app:req}

The best way to demonstrate the use of a framework is through example.
Hence, through the course of this thesis, we present a music player
application and show how different elements of it may be developed
using DynamiTE.  At this juncture, we specify the requirements for it
as follows:

\begin{itemize}
\item The application should provide some form of interface with which
  the user can interact.
\item It should be able to take a wave file and return a sequence of
  sound data for playback.
\item It should be able to output the sound data through the speakers.
\item It should be able to generate a spectral analysis of the sound
  data as a form of visual feedback.
\end{itemize}

This is a minimal set, but is more than enough to demonstrate the
process of building up an application.  Further features could be
added, such as playlists, more visualisations, support for further
file formats, the use of tags and web services to provide song
metadata, etc.

Central to designing an application with DynamiTE is keeping two
things in mind; firstly, the application should be composed of
components, each capable of performing their own task, and secondly,
the application itself should be capable of being used as a component
by others.  The latter comes with the implicit assumption that the
application's features are accessible by others, and that it remains
relatively lightweight so as not to introduce unnecessary and
burdensome requirements.

In an object-oriented application design, the focus would be on the
data i.e. the songs being played.  With a focus on function, we
instead split the application up by task as follows:

\begin{itemize}
\item The \texttt{Inputter} receives a file name as input, and
  produces a stream of wave data from it as output.
\item The \texttt{Outputter} recieves a stream of wave data as input
  and produces output via the speakers.
\item The \texttt{Visualiser} receives a stream of wave data as input
  and produces a graphical display as output.
\item The \texttt{Interface} receives input from the user and uses
  this to provide input to and control the ohter components.
\end{itemize}

In later chapters, we will demonstrate how these components can be
formally modelled using our process calculus and how they may be
implemented using DynamiTE.

\section{Structure of the Thesis}

The first half of this thesis focuses on existing research in order to
provide the necessary background material for the novel work presented
in later chapters.  Through this evaluation, we make clear the
motivation for our work and also allow this thesis to remain
relatively self-contained.  In the next chapter, we introduce existing
research in to the area of algebraic process calculi through an
exploration of the Calculus of Concurrent Systems (CCS)
\cite{milner:ccs}.  The following two chapters then focus on specific
extensions to such calculi: global synchronisation (\ref{globsync})
and mobility (\ref{mobility}).

In chapter \ref{nt}, we introduce our own research in the form of the
Nomadic Time process calculus, while chapter \ref{dynamite} covers the
development of the DynamiTE (Dynamic Theory Execution) framework.  The
following chapter (\ref{tnt}) demonstrates how Nomadic Time may
optionally be extended with a type system to create TNT (Typed Nomadic
Time).  Both of the latter two chapters also cover related work in
these particular areas.  We close with suggestions for future work in
chapter \ref{futurework}.

\section{Contributions to Knowledge}

Through this thesis, we present the following contributions to
knowledge which we believe to be novel:

\begin{enumerate}
\item The development of Nomadic Time, an algebraic process calculus
  with \emph{compositional global synchronisation}, \emph{mobility}
  and security provision via the notion of `\emph{bouncers}'
  (see chapter \ref{nt}).
\item The realisation of the aforementioned calculus as a \emph{design
  framework}, DynamiTE, through the implementation of its constructs
  as programmatic elements in the Java programming language (see
  chapter \ref{dynamite}).  This allows the specification of system
  interactions to be shifted directly from the theoretical domain into
  an implementation backed by a formal methodology, helping in turn to
  improve industrial adoption of concurrent techniques.
\item The optional addition of a \emph{type system} to Nomadic Time in
  order to allow movement restriction to be based on the group
  membership of processes (see chapter \ref{tnt}); we refer to this
  extended version as Typed Nomadic Time (TNT).
\end{enumerate}

This work has already produced two peer-reviewed papers \cite{nt,
  dynamite} and several presentations, both internal and external (at
the British Colloquium of Theoretical Computer Science (BCTCS) 2006,
the Relational Methods in Computer Science (RelMiCS) PhD workshop
2006, the University of York and Principles and Practice of
Programming in Java (PPPJ) 2007).
