% Thesis: DynamiTE
% Author: Andrew Hughes

\chapter{The DynamiTE Framework}
\label{dynamite}

\section{Introduction}

\section{Mapping Theory to Practicality}
\label{dyn:maptheory}

DynamiTE uses the TNT process calculus described above as the basis for
a concurrent object-oriented framework.  Within this framework,
developers can create concurrent applications simply by implementing the
specific behaviour they require in appropriate subclasses.  Each
syntactic construct is mapped to an appropriate Java class, which
provides the required functionality and relates to others via a common
\texttt{Process} superclass.  Operation follows a top-down approach; the
complete system is represented by a single instance of one of these
classes which, in most cases, will be an operator that composes together
further instances as appropriate.

The simplest \texttt{Process} subclass is the representation of $\nil$,
realised as a class \texttt{Nil} which provides process termination.
The internal action $\tau$ is realised as an abstract class \texttt{Tau}
and this is where the user can implement arbitrary sequential behaviour
as required, by providing a subclass. The observable actions form part
of the channel subsystem, described in \ref{dyn:channels}.

The $+$ operator is implemented as a class which contains a list of
subprocesses from which one is chosen at random.  The action to perform
is computed by traversing the hierarchy, so restriction is simply a
matter of providing appropriate filtering, thus preventing the
restricted names from travelling further up the hierarchy.

More interesting is the \texttt{Par} class which implements the $\mid$
operator, as it must allow its subprocesses to operate concurrently.
The most obvious way to achieve this is by mapping individual processes
onto Java threads.  This also means that data can be stored with the
process by means of thread-local variables.  However, we are keen to
offer flexibility in how the individual features of the framework are
implemented.  Java thread mapping is only one way in which concurrent
processing may be implemented and so we abstract away \texttt{Par} from
the threading implementation as much as possible, thus allowing it to be
replaced by other implementations at a later date.  For example,
concurrent processing could also be provided by distinct processes
spawned by the VM or a more complex distributed solution may become
apparent.

\section{The Channel Abstraction}
\label{dyn:channels}

In the same vein, the implementation of synchronisation channels is
abstracted in such as way as to allow for differing implementations.
Here, the provision of multiple implementations is more prevalent and so
a plugin mechanism is already present.  Fortunately, Java already has
plenty of support for plugin based frameworks (imaging and sound already
being implemented in this fashion) and the new
\texttt{java.util.ServiceLoader} API provided in 1.6 makes this simpler
still.  This allows the user to have freedom of choice with respect to
their chosen channel implementation, which may even be further extended
by their own or third-party plugins.

At its simplest, DynamiTE provides a way of testing TNT processes and
ensuring they perform as expected.  In this respect, the simplest
channel plugin is a dummy channel, which need do nothing more than
simply exist.  More complex solutions are of course possible and are
needed to make the framework both usable and interesting.  

Although currently there is no realisation of data within the formal
layer of the calculus, this only matters to the extent that we wish
transmitted data to alter the constructs themselves via
substitution\footnote{The $\pi$ calculus \cite{picalctutorial} is an
obvious example of such behaviour, which goes to the extreme of not only
allowing data to be transferred but also references to channels which
can then later be used in the language constructs.  This, in essence,
provides the form of mobility present in the $\pi$ calculus.}.  Data can
be transferred between processes and used within internal actions
without having to be explicitly realised at the formal level.  There are
a multitude of ways of implementing data transfer, ranging from simple
mechanisms like files and sockets to more full-blown interprocess
communication protocols such as Java's Remote Method Invocation (RMI),
the Common Object Request Broker Architecture (CORBA) and web services.
The plugin nature of the channel architecture means that any of these
possibilities may be used and more besides.

While the implementations of the channels themselves can provide the
input and output mechanisms, interoperability between the two has to
take place at a higher level.  Thus, the onus is on the parallel
implementation, \texttt{Par}, to co-ordinate the communication between
the two, by virtue of discovering which names are exposed at the point
of composition.

A possible simplification becomes apparent here, as some implementations
may make use of channel naming.  For example, if the channel name refers
to a host and port for a TCP/IP implementation, then the sender need
only try and connect to see if a recipient is available.  Channel names
are assumed to be unique, so such a mapping is possible.  However, they
are not unique to a particular process, making it perfectly plausible
for the channel name to occur simultaneously on multiple processes and
thus for a competition to occur.  There is also the issue of whether
they can actually `see' each other, according to the constraints of the
calculus, so the decision should still be left to an appropriate
parallel composition operator.

\section{Signalling}
\label{dyn:signalling}

One of the most interesting parts of the DynamiTE framework is the
implementation of clock signals.  While there have been other attempts
to produce frameworks or languages based on process calculi (see section
\ref{dyn:relatedwork}), we believe that the rendering of discrete time into
such a context is novel.

The first question to answer when attempting to perform such a
translation is where to actually locate the clocks.  Within TNT, the
obvious answer is within each environ, as these are responsible for
providing the division between processes which can observe clock ticks
and those which can not.  For example, the following environ
\begin{displaymath}
\loc{m}{P}{\Omega}{\sigma}
\end{displaymath}
would be realised as an instance of the \texttt{Environ} class with the
name $m$.  This instance would maintain a reference to the process $P$
with which it interacts.  Not only is the execution of $P$ controlled by
the environ (as with the implementations of $+$ and $\mid$ above), but
it also controls when and how the ticks of $\sigma$ reach $P$.

Recall our earlier description of the calculus, where we mentioned how
clock ticks are always pre-empted by high priority actions, which may
arise either from explicit internal actions denoted by $\tau$, implicit
internal actions caused by synchronisation or movement.  So, in order
for the environ to know whether to propagate a clock tick to the
process, it must first probe it to find out whether such a high priority
action is pending.  Clock ticks may also be prevented by the $\Delta$
and $\Delta_\sigma$ constructs, so these must also be checked for.

Both can actually be achieved in one transaction by making the probe the
clock tick.  The clock tick is sent down the process hierarchy until it
reaches a point at which a decision can be made as to whether the tick
should occur or not.  If the tick can occur, it is propagated back up
the hierarchy, eventually stopping when it reaches its host environ
again.  The host environ can be determined by the set of clocks
associated with each environ, which is also used to calculate the
signals to be propagated initially.  If the clock is not allowed to
tick, then the actual action performed is sent instead.

This algorithm is best explained by a couple of prototypical examples.
First, consider 
\begin{displaymath}
\loc{m}{a.\nil + b.\nil}{\Omega}{\sigma}
\end{displaymath}
where the process inside $m$ has no $\tau$ actions, synchronisations,
mobility or clock stop operators, and thus clearly allows the clock
$\sigma$ to tick.  The environ $m$ iterates over its set of clocks (here
just $\sigma$), and sends a tick from each to its process, $a.\nil +
b.\nil$.

This process is realised by an instance of the \texttt{Sum} class, which
composes the two processes together.  A clock can only tick over the
summation operator if it can tick over both sides, so the result from
this instance is simply the result of combining the return value from
probing each of the constituent processes.

Both $a.\nil$ and $b.\nil$ are implemented using instances of the
\texttt{Prefix} class, which composes a \texttt{Channel}\footnote{An
abstract class, instances of which are provided by the channel
architecture described in \ref{dyn:channels}} or \texttt{Tau} instance
(unified by the \texttt{Action} class) with another instance of a
\texttt{Process} subclass.  In determining whether a clock can tick, it
first checks that the action is a channel rather than a \texttt{Tau}
instance (which would pre-empt the clock), and then probes the
\texttt{Process} instance.  In both these simple cases, this is an
instance of \texttt{Nil}, which allows clock ticks.

Having determined that the clock may tick, each nested call returns with
the $\sigma$ clock tick, thus propagating it up to the original call in
the environ $m$.  Having seen how this operates for a process that can
tick, it is simple to see how it differs when something prevents the
clock from ticking.  If any part of the query returns something other
than a clock tick, this will be propagated upwards in preference.

Consider what happens if $a.\nil$ is changed to $\tau.\nil$.  The
left-hand side of the summation will receive the $\tau$ action from the
\texttt{Prefix} instance, which then takes priority over the $\sigma$
from the right-hand side and is propagated to the environ, $m$.  This is
the case in any situation where the $\sigma$ is required to compete
against an action, a $\tau$ or a mobility primitive.  The clock stop
operators behave slightly differently in that they don't replace the
action, but instead mark the $\sigma$ action as \emph{stopped}.

Note that a similar method of determining the presence of clock ticks
must take place to handle the \texttt{STimeout} and \texttt{FTimeout}
classes.  Both sides of the timeout are inspected, and behaviour
determined as follows:
\begin{enumerate}
\item If the left-hand side can perform a high-priority action, it will
      be allowed to proceed and the right-hand side need not be
      considered.
\item Otherwise, the possible actions include unpaired actions (such as
      $a$ and $b$) and clock ticks (both from the clock involved in the
      timeout and from other clocks), one of which is chosen to be
      performed.
\item Once the chosen action has been performed, the timeout instance
      will be replaced as appropriate (see chapter \ref{nt}). 
\end{enumerate}

\section{Structural Changes}
\label{dyn:structchange}

The \texttt{Environ} class also places a central role in providing
system structure.  In chapter \ref{nt}, we described how
processes are organised into environs and the way communication is
limited to its bounds.  Within DynamiTE, one possible use of environs
is to map them to physical or virtual hosts.  While a simple testing
solution can execute the entire system on a single platform, environs
provide a natural form of process distribution which can be leveraged by
the framework.

This does however give the initial impression that structural mobility
will become very inefficient, if hosts are expected to interact to
determine the feasibility of a move and then actually change position
during execution.  In reality, these issues are minimal.  An inward
movement is always in relation to a sibling, while an outward movement
concerns some parent environ.  As the structure of environs is expected
to closely match the actual physical structure of the hosts, such
interactions should be relatively low cost to perform.  Also, a
structural movement does not change the contents of the moving environ,
only its context.  Thus, only later communication with surrounding
environs is affected.  For example, it may have been able to see a
sibling environ before the movement, but is now inside this environ and
can receive clock ticks emitted by it.

If hosts do not physically move, then what is the point in allowing such
structural changes?  The change in clock signalling just mentioned is
one effect.  In addition, we also make provision for contextual data to
be stored at the environ level, in addition to that stored local to a
particular thread, and transferred via channels.  This gives additional
purpose to the use of structural mobility and process migration, which
we describe next.

\section{Migration}
\label{dyn:migration}

The final aspect of DynamiTE that we describe here is the migration of a
process from one environ to another, which occurs both as a result of
using one of the process mobility operators and from the behaviour of
$\tntopen$.  This is perhaps one of the most interesting aspects, as it
represents the movement of code from one environment to another,
possibly located in a different physical location.

Migrating an active process is not a simple operation.  Not only must
any remaining code to be executed be transferred, but any local data
must also migrate.  TNT does allow us to achieve a significant amount of
simplification here.  The transferred process is already separated from
other code within the system by virtue of the moving process being in
the form of a \texttt{Prefix} instance.  When the action is matched to
the one used for the mobility operation, the \texttt{Process} instance
is transferred to its new location.  There is no necessity to deal with
code that is currently being executed.

As with concurrency and channel operation, how movement is achieved is
designed to be flexible, with provision being made for distribution and
code migration to be implemented in different ways.  One of the most
obvious ways is to serialise the \texttt{Process} instance and
reconstitute it at its destination.  Migrating a process should then
just be a case of transmitting the serialised instance, followed by any
local data, and beginning execution at the destination.  However, this
is one area in which we expect further study of the existing literature
to enlighten us with more sophisticated ways of achieving such
migration.

\section{Related Work}
\label{dyn:relatedwork}

There has already been a significant body of research into providing
concurrent frameworks, including those based on process calculi.
However, we believe our work to be novel in approaching the
implementation of both global discrete time, via clock signalling, and
mobility.

The $\pi$ calculus has been the subject of much of this work, primarily
due to its status as the most prevalant mobile process calculus.  Obliq
\cite{obliq} and Pict \cite{daveturner:phd} are both programming
languages with semantics founded in the $\pi$ calculus, while Nomadic
Pict \cite{wojciechowski:phd} takes this further, introducing
distribution not usually present in the $\pi$ calculus.  Within research
related to the ambient calculus, a machine framework (PAN
cite{sangiorgi:safeambientsmachine}) has been developed and
implemented.  Process calculi, such as the Seal calculus \cite{seal}
have also been developed specifically to provide a formal framework for
a distributed implementation.
%The $\pi$ calculus has been the subject of much of this work, primarily
%due to its status as the most prevalent mobile process calculus.  Obliq
%\cite{obliq} and Pict \cite{daveturner:phd} are both programming
%languages with semantics founded in the $\pi$ calculus, while a machine
%framework (PAN \cite{sangiorgi:safeambientsmachine}) has been developed
%and implemented for the ambient calculus.

\section{Conclusion}
