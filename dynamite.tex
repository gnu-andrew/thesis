% Thesis: DynamiTE
% Author: Andrew Hughes

\chapter{The DynamiTE Framework}
\label{dynamite}

\section{Introduction}

In this chapter, we introduce DynamiTE, the Dynamic Theory Execution
framework.  This provides the solution we first proposed in
\ref{solution}, using the calculus introduced in \ref{nt} and
\ref{tnt} as a foundation for application development.  Through using
DynamiTE, programmers compose TNT processes, realised as Java objects,
to create a working system.  The framework handles running these
processes, in parallel if necessary, and negotiates the communication
between them.  Both features are provided by leveraging existing
facilities in the underlying Java virtual machine and class library.

Over the course of this chapter, we will describe how TNT processes
are mapped onto Java objects (see \ref{dyn:maptheory}) and then show
how DynamiTE can be used to create an implementation of the
application we introduced in \ref{protoapp} (see \ref{app:dynamite}).
But first, we discuss why we chose Java as the host language for
DynamiTE and what advantages and disadvantages this brings to its
implementation.

\section{Why Java?}

The first implementation of the Java programming language was released
in 1995 by Sun Microsystems.  It takes the form of a block structured
language with a syntax akin to C or C++.  However, unlike programs
written in those languages, Java applications tend to be compiled to
platform-independent Java bytecodes which are then executed by a Java
Virtual Machine or JVM.  This allows the same Java program to be
executed on multiple platforms without the need for recompilation.
With this new operating environment comes the removal of a number of
features found in Java's predecessors and the restriction of others,
with the aim of creating a safer and more portable language:

\begin{itemize}
\item \textbf{No pointer manipulation}.  All primitive types in Java
  (integer, floating point numbers, booleans and single characters)
  are passed by value.  All objects are stored and passed as pointers
  or references to their location in memory.  These pointers are
  immutable, removing the ability to perform pointer arthimetic
  (e.g. for iterating over arrays) and with it, a host of problems
  inherent with inappropriate memory access.  For example, attempts to
  use a \texttt{null} pointer are caught by the virtual machine and
  produce a checked exception, rather than causing a segmentation
  fault which brings down the entire process.
\item \textbf{All arrays are bounds checked}.  A major cause of errors
  and security issues in C and C++ programs is the possibility of
  buffer overflows, where programs write to memory beyond the end of
  an array.  In Java, such errors are prevented by the virtual
  machine; any attempt to access an index outside the bounds of an
  array causes a checked exception to be thrown and direct access to
  the array's memory is forbidden by the lack of pointer manipulation.
\item \textbf{All memory management is performed by a garbage
  collector}.  While allowing manual memory management allows the
  programmer greater control, it leads to an equivalent to the issue
  we saw with semaphores in \ref{semaphores}; every allocation must be
  paired with a later deallocation to avoid the possibility of an
  application leaking memory.  The problem is even more pronounced
  with regard to memory management as, while the acquisition and
  release of a lock tend to occur in close proximity to one another,
  allocation and deallocation can occur in quite disparate parts of
  the application.  In Java, memory is instead managed by a
  \emph{garbage collector} which allocates memory for objects as
  needed and periodically reclaims those that are no longer
  referenced.  The downside of this is that the garbage collector has
  to use processor time to perform its scans which would otherwise be
  used by the application.  However, as new garbage collection
  techniques, such as concurrent and generational collectors, become
  prevalent, this disadvantage is further outweighed by the prospect
  of chasing memory leaks.
\item \textbf{Lack of unsigned types}.  All integer types in Java use
  a bit to store the sign of the value, with no equivalent unsigned
  types that instead use this bit to store larger values.  This makes
  bitwise operations (and (\texttt{\&}), or(\texttt{|}) and
  not(\texttt{\~})) more inefficient as they need to operate on the
  type one size above (bytes ($2^8$) on shorts ($2^{16}$), shorts on
  ints ($2^{32}$), etc.).  Indeed, the Java
  specification\cite{javaspec} specifies that the operands should be
  converted to integer or long integer levels of precision before the
  operation is performed.  Thus, it logically follows that it is
  impossible to work with unsigned long integers ($2^64$) without
  resorting to the overhead of a class which implements arbitrary
  precision integers, such as \texttt{java.lang.BigInteger}.  Unsigned
  types continue to be proposed for addition to the Java language, but
  no such extension is scheduled for the next release (Java 7).
\end{itemize}

Although these changes are made at the expense of flexibility for the
programmer and possible efficency gains, they save time overall in
chasing bugs caused by memory allocation errors, buffer overflows or
leaks.  Besides, the Java Native Interface (JNI) can be used to
implement certain methods in C, should the need arise.  Many of the
methods provided by the Java class library do just that, usually to
make use of a platform-specific application programming interface
(API).  Doing so has some overhead and means losing the safety and
memory management benefits of Java, but is possible where necessary.

Performance has been a common criticism of Java, not just because of
these features but also because the Java bytecodes it uses must be
either interpreted or compiled into native code at run time.  This is
much less of an issue than it once was, due to advances in virtual
machine design and Just-In-Time (JIT) compilation techniques.
Theoretically, JIT compilation should eventually exceed the
performance of code compiled Ahead-Of-Time (AOT) as it can take
advantage of information only available at runtime.  This includes
knowing the exact platform on which the code will execute and being
able to make better optimisations based on statistics gathered through
execution (e.g. better branch prediction).  For example, HotSpot, the
virtual machine used by Sun's implementation of Java, only uses the
JIT compiler to create native code when it believes the code is used
enough (`hot' enough) to make doing so worthwhile.

Of these changes, the absence of unsigned types is the only one that
seems to have no advantage, other than simplifing the language.  Many
file formats and network protocols include unsigned types, so working
with them in Java becomes harder than is necessary.  Although their
absence may have made sense in earlier versions of the language, the
complexity of understanding unsigned arithmetic now seems trivial when
compared with the existential type system and its reification added by
the introduction of `\emph{generics}' in Java 5.  We thus hope that
they may make an appearance in Java 8.

\subsection{Concurrency in Java}

From the perspective of implementing DynamiTE, one advantage of Java
is its broad support for concurrency.  Java is one of the few
languages to have an implementation of \emph{monitors}, a feature we
demonstrated in \ref{semaphores}.

\section{Mapping Theory to Practicality}
\label{dyn:maptheory}

DynamiTE uses the TNT process calculus described above as the basis for
a concurrent object-oriented framework.  Within this framework,
developers can create concurrent applications simply by implementing the
specific behaviour they require in appropriate subclasses.  Each
syntactic construct is mapped to an appropriate Java class, which
provides the required functionality and relates to others via a common
\texttt{Process} superclass.  Operation follows a top-down approach; the
complete system is represented by a single instance of one of these
classes which, in most cases, will be an operator that composes together
further instances as appropriate.

The simplest \texttt{Process} subclass is the representation of $\nil$,
realised as a class \texttt{Nil} which provides process termination.
The internal action $\tau$ is realised as an abstract class \texttt{Tau}
and this is where the user can implement arbitrary sequential behaviour
as required, by providing a subclass. The observable actions form part
of the channel subsystem, described in \ref{dyn:channels}.

The $+$ operator is implemented as a class which contains a list of
subprocesses from which one is chosen at random.  The action to perform
is computed by traversing the hierarchy, so restriction is simply a
matter of providing appropriate filtering, thus preventing the
restricted names from travelling further up the hierarchy.

More interesting is the \texttt{Par} class which implements the $\mid$
operator, as it must allow its subprocesses to operate concurrently.
The most obvious way to achieve this is by mapping individual processes
onto Java threads.  This also means that data can be stored with the
process by means of thread-local variables.  However, we are keen to
offer flexibility in how the individual features of the framework are
implemented.  Java thread mapping is only one way in which concurrent
processing may be implemented and so we abstract away \texttt{Par} from
the threading implementation as much as possible, thus allowing it to be
replaced by other implementations at a later date.  For example,
concurrent processing could also be provided by distinct processes
spawned by the VM or a more complex distributed solution may become
apparent.

\subsection{The Channel Abstraction}
\label{dyn:channels}

In the same vein, the implementation of synchronisation channels is
abstracted in such as way as to allow for differing implementations.
Here, the provision of multiple implementations is more prevalent and so
a plugin mechanism is already present.  Fortunately, Java already has
plenty of support for plugin based frameworks (imaging and sound already
being implemented in this fashion) and the new
\texttt{java.util.ServiceLoader} API provided in 1.6 makes this simpler
still.  This allows the user to have freedom of choice with respect to
their chosen channel implementation, which may even be further extended
by their own or third-party plugins.

At its simplest, DynamiTE provides a way of testing TNT processes and
ensuring they perform as expected.  In this respect, the simplest
channel plugin is a dummy channel, which need do nothing more than
simply exist.  More complex solutions are of course possible and are
needed to make the framework both usable and interesting.  

Although currently there is no realisation of data within the formal
layer of the calculus, this only matters to the extent that we wish
transmitted data to alter the constructs themselves via
substitution\footnote{The $\pi$ calculus \cite{picalctutorial} is an
obvious example of such behaviour, which goes to the extreme of not only
allowing data to be transferred but also references to channels which
can then later be used in the language constructs.  This, in essence,
provides the form of mobility present in the $\pi$ calculus.}.  Data can
be transferred between processes and used within internal actions
without having to be explicitly realised at the formal level.  There are
a multitude of ways of implementing data transfer, ranging from simple
mechanisms like files and sockets to more full-blown interprocess
communication protocols such as Java's Remote Method Invocation (RMI),
the Common Object Request Broker Architecture (CORBA) and web services.
The plugin nature of the channel architecture means that any of these
possibilities may be used and more besides.

While the implementations of the channels themselves can provide the
input and output mechanisms, interoperability between the two has to
take place at a higher level.  Thus, the onus is on the parallel
implementation, \texttt{Par}, to co-ordinate the communication between
the two, by virtue of discovering which names are exposed at the point
of composition.

A possible simplification becomes apparent here, as some implementations
may make use of channel naming.  For example, if the channel name refers
to a host and port for a TCP/IP implementation, then the sender need
only try and connect to see if a recipient is available.  Channel names
are assumed to be unique, so such a mapping is possible.  However, they
are not unique to a particular process, making it perfectly plausible
for the channel name to occur simultaneously on multiple processes and
thus for a competition to occur.  There is also the issue of whether
they can actually `see' each other, according to the constraints of the
calculus, so the decision should still be left to an appropriate
parallel composition operator.

\subsection{Signalling}
\label{dyn:signalling}

One of the most interesting parts of the DynamiTE framework is the
implementation of clock signals.  While there have been other attempts
to produce frameworks or languages based on process calculi (see section
\ref{dyn:relatedwork}), we believe that the rendering of discrete time into
such a context is novel.

The first question to answer when attempting to perform such a
translation is where to actually locate the clocks.  Within TNT, the
obvious answer is within each environ, as these are responsible for
providing the division between processes which can observe clock ticks
and those which can not.  For example, the following environ
\begin{displaymath}
\loc{m}{P}{\Omega}{\sigma}
\end{displaymath}
would be realised as an instance of the \texttt{Environ} class with the
name $m$.  This instance would maintain a reference to the process $P$
with which it interacts.  Not only is the execution of $P$ controlled by
the environ (as with the implementations of $+$ and $\mid$ above), but
it also controls when and how the ticks of $\sigma$ reach $P$.

Recall our earlier description of the calculus, where we mentioned how
clock ticks are always pre-empted by high priority actions, which may
arise either from explicit internal actions denoted by $\tau$, implicit
internal actions caused by synchronisation or movement.  So, in order
for the environ to know whether to propagate a clock tick to the
process, it must first probe it to find out whether such a high priority
action is pending.  Clock ticks may also be prevented by the $\Delta$
and $\Delta_\sigma$ constructs, so these must also be checked for.

Both can actually be achieved in one transaction by making the probe the
clock tick.  The clock tick is sent down the process hierarchy until it
reaches a point at which a decision can be made as to whether the tick
should occur or not.  If the tick can occur, it is propagated back up
the hierarchy, eventually stopping when it reaches its host environ
again.  The host environ can be determined by the set of clocks
associated with each environ, which is also used to calculate the
signals to be propagated initially.  If the clock is not allowed to
tick, then the actual action performed is sent instead.

This algorithm is best explained by a couple of prototypical examples.
First, consider 
\begin{displaymath}
\loc{m}{a.\nil + b.\nil}{\Omega}{\sigma}
\end{displaymath}
where the process inside $m$ has no $\tau$ actions, synchronisations,
mobility or clock stop operators, and thus clearly allows the clock
$\sigma$ to tick.  The environ $m$ iterates over its set of clocks (here
just $\sigma$), and sends a tick from each to its process, $a.\nil +
b.\nil$.

This process is realised by an instance of the \texttt{Sum} class, which
composes the two processes together.  A clock can only tick over the
summation operator if it can tick over both sides, so the result from
this instance is simply the result of combining the return value from
probing each of the constituent processes.

Both $a.\nil$ and $b.\nil$ are implemented using instances of the
\texttt{Prefix} class, which composes a \texttt{Channel}\footnote{An
abstract class, instances of which are provided by the channel
architecture described in \ref{dyn:channels}} or \texttt{Tau} instance
(unified by the \texttt{Action} class) with another instance of a
\texttt{Process} subclass.  In determining whether a clock can tick, it
first checks that the action is a channel rather than a \texttt{Tau}
instance (which would pre-empt the clock), and then probes the
\texttt{Process} instance.  In both these simple cases, this is an
instance of \texttt{Nil}, which allows clock ticks.

Having determined that the clock may tick, each nested call returns with
the $\sigma$ clock tick, thus propagating it up to the original call in
the environ $m$.  Having seen how this operates for a process that can
tick, it is simple to see how it differs when something prevents the
clock from ticking.  If any part of the query returns something other
than a clock tick, this will be propagated upwards in preference.

Consider what happens if $a.\nil$ is changed to $\tau.\nil$.  The
left-hand side of the summation will receive the $\tau$ action from the
\texttt{Prefix} instance, which then takes priority over the $\sigma$
from the right-hand side and is propagated to the environ, $m$.  This is
the case in any situation where the $\sigma$ is required to compete
against an action, a $\tau$ or a mobility primitive.  The clock stop
operators behave slightly differently in that they don't replace the
action, but instead mark the $\sigma$ action as \emph{stopped}.

Note that a similar method of determining the presence of clock ticks
must take place to handle the \texttt{STimeout} and \texttt{FTimeout}
classes.  Both sides of the timeout are inspected, and behaviour
determined as follows:
\begin{enumerate}
\item If the left-hand side can perform a high-priority action, it will
      be allowed to proceed and the right-hand side need not be
      considered.
\item Otherwise, the possible actions include unpaired actions (such as
      $a$ and $b$) and clock ticks (both from the clock involved in the
      timeout and from other clocks), one of which is chosen to be
      performed.
\item Once the chosen action has been performed, the timeout instance
      will be replaced as appropriate (see chapter \ref{nt}). 
\end{enumerate}

\subsection{Structural Changes}
\label{dyn:structchange}

The \texttt{Environ} class also places a central role in providing
system structure.  In chapter \ref{nt}, we described how
processes are organised into environs and the way communication is
limited to its bounds.  Within DynamiTE, one possible use of environs
is to map them to physical or virtual hosts.  While a simple testing
solution can execute the entire system on a single platform, environs
provide a natural form of process distribution which can be leveraged by
the framework.

This does however give the initial impression that structural mobility
will become very inefficient, if hosts are expected to interact to
determine the feasibility of a move and then actually change position
during execution.  In reality, these issues are minimal.  An inward
movement is always in relation to a sibling, while an outward movement
concerns some parent environ.  As the structure of environs is expected
to closely match the actual physical structure of the hosts, such
interactions should be relatively low cost to perform.  Also, a
structural movement does not change the contents of the moving environ,
only its context.  Thus, only later communication with surrounding
environs is affected.  For example, it may have been able to see a
sibling environ before the movement, but is now inside this environ and
can receive clock ticks emitted by it.

If hosts do not physically move, then what is the point in allowing such
structural changes?  The change in clock signalling just mentioned is
one effect.  In addition, we also make provision for contextual data to
be stored at the environ level, in addition to that stored local to a
particular thread, and transferred via channels.  This gives additional
purpose to the use of structural mobility and process migration, which
we describe next.

\subsection{Migration}
\label{dyn:migration}

The final aspect of DynamiTE that we describe here is the migration of a
process from one environ to another, which occurs both as a result of
using one of the process mobility operators and from the behaviour of
$\tntopen$.  This is perhaps one of the most interesting aspects, as it
represents the movement of code from one environment to another,
possibly located in a different physical location.

Migrating an active process is not a simple operation.  Not only must
any remaining code to be executed be transferred, but any local data
must also migrate.  TNT does allow us to achieve a significant amount of
simplification here.  The transferred process is already separated from
other code within the system by virtue of the moving process being in
the form of a \texttt{Prefix} instance.  When the action is matched to
the one used for the mobility operation, the \texttt{Process} instance
is transferred to its new location.  There is no necessity to deal with
code that is currently being executed.

As with concurrency and channel operation, how movement is achieved is
designed to be flexible, with provision being made for distribution and
code migration to be implemented in different ways.  One of the most
obvious ways is to serialise the \texttt{Process} instance and
reconstitute it at its destination.  Migrating a process should then
just be a case of transmitting the serialised instance, followed by any
local data, and beginning execution at the destination.  However, this
is one area in which we expect further study of the existing literature
to enlighten us with more sophisticated ways of achieving such
migration.

\section{A Prototypical Application in DynamiTE}
\label{app:dynamite}
                                   
\section{Related Work}
\label{dyn:relatedwork}

There has already been a significant body of research into providing
concurrent frameworks, including those based on process calculi.
However, we believe our work to be novel in approaching the
implementation of both global discrete time, via clock signalling, and
mobility.

The $\pi$ calculus has been the subject of much of this work, primarily
due to its status as the most prevalant mobile process calculus.  Obliq
\cite{obliq} and Pict \cite{daveturner:phd} are both programming
languages with semantics founded in the $\pi$ calculus, while Nomadic
Pict \cite{wojciechowski:phd} takes this further, introducing
distribution not usually present in the $\pi$ calculus.  Within research
related to the ambient calculus, a machine framework (PAN
cite{sangiorgi:safeambientsmachine}) has been developed and
implemented.  Process calculi, such as the Seal calculus \cite{seal}
have also been developed specifically to provide a formal framework for
a distributed implementation.
%The $\pi$ calculus has been the subject of much of this work, primarily
%due to its status as the most prevalent mobile process calculus.  Obliq
%\cite{obliq} and Pict \cite{daveturner:phd} are both programming
%languages with semantics founded in the $\pi$ calculus, while a machine
%framework (PAN \cite{sangiorgi:safeambientsmachine}) has been developed
%and implemented for the ambient calculus.

\section{Conclusion}
